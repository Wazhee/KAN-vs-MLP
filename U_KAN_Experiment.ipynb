{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTotgNTSO0ITpqBYpENX9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wazhee/KAN-vs-MLP/blob/main/U_KAN_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is KAN?\n",
        "\n",
        "## Kolmogorov-Arnold Networks\n",
        "##### New class of neural networks aimed to be more less prone to overfitting and more interpretable than multi-layer perceptrons\n",
        "\n",
        "##### In this experiment we see if KAN can truly outperform MLP in segmentation tasks. I conduct the following experiments:\n",
        "- Train U-KAN (using KAN) and U-Net (using MLP) architectures on Brats2023 Brain MRI segmentation dataset\n",
        "- Evaluate U-KAN and U-Net dice similarity performance\n",
        "- Evaluate U-KAN and U-Nets sensitivity to sample size and number of epochs\n",
        "- Evaluate U-KAN and U-Net computational load\n",
        "\n",
        "<img src='https://drive.google.com/file/d/1uS2mrRleKRhyF_3An_qaalMLMvU5hFqZ/view?usp=drive_link' style=\"height:115px\">"
      ],
      "metadata": {
        "id": "SShBsC2geTi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load U-KAN Repository"
      ],
      "metadata": {
        "id": "4Pg2bE5xiDQV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpP8DrCUeQW8",
        "outputId": "318bbbf2-40c5-4ff0-c687-776b4139a3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'U-KAN'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 193 (delta 21), reused 15 (delta 13), pack-reused 159 (from 1)\u001b[K\n",
            "Receiving objects: 100% (193/193), 2.58 MiB | 29.30 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CUHK-AIM-Group/U-KAN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd U-KAN\n",
        "!cd Seg_UKAN && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSdH3ZqiB7A",
        "outputId": "185a0af1-18f0-47ee-b6c6-ef386ef75865"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: Seg_UKAN: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install addict==2.4.0\n",
        "# !pip install dataclasses\n",
        "# !pip install pandas\n",
        "# !pip install pyyaml\n",
        "# !pip install albumentations\n",
        "# !pip install tqdm\n",
        "# !pip install\n",
        "# !pip install numpy\n",
        "# !pip install opencv-python\n",
        "# !pip install perceptual==0.1\n",
        "# !pip install pillow==8.4.0\n",
        "# !pip install scikit-image==0.17.2\n",
        "# !pip install scipy==1.5.4\n",
        "# !pip install tifffile==2020.9.3\n",
        "# !pip install timm==0.3.2\n",
        "# !pip install typing-extensions==4.0.0\n",
        "# !pip install yapf==0.31.0\n",
        "\n",
        "#!pip install timm\n",
        "#!pip install MedPy\n",
        "!pip install tensorboardX\n",
        "#!pip install typing_extensions\n",
        "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32vn9ubViTsB",
        "outputId": "5e7d1449-dba0-453d-b704-bb22afdc3f2e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python train.py --arch UKAN --dataset {dataset} --input_w {input_size} --input_h {input_size} --name {dataset}_UKAN  --data_dir [YOUR_DATA_DIR]\n",
        "!python 'U-KAN/Seg_UKAN/train.py' --arch UKAN --dataset {dataset} --input_w 128 --input_h 128 --name {dataset}_UKAN  --data_dir [YOUR_DATA_DIR]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnJDwnyRiUI2",
        "outputId": "ca78f1c5-6430-41ef-e479-bb6dbf6948bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "--------------------\n",
            "name: {dataset}_UKAN\n",
            "epochs: 400\n",
            "batch_size: 8\n",
            "dataseed: 2981\n",
            "arch: UKAN\n",
            "deep_supervision: False\n",
            "input_channels: 3\n",
            "num_classes: 1\n",
            "input_w: 128\n",
            "input_h: 128\n",
            "input_list: [128, 160, 256]\n",
            "loss: BCEDiceLoss\n",
            "dataset: {dataset}\n",
            "data_dir: [YOUR_DATA_DIR]\n",
            "output_dir: outputs\n",
            "optimizer: Adam\n",
            "lr: 0.0001\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0001\n",
            "nesterov: False\n",
            "kan_lr: 0.01\n",
            "kan_weight_decay: 0.0001\n",
            "scheduler: CosineAnnealingLR\n",
            "min_lr: 1e-05\n",
            "factor: 0.1\n",
            "patience: 2\n",
            "milestones: 1,2\n",
            "gamma: 0.6666666666666666\n",
            "early_stopping: -1\n",
            "cfg: None\n",
            "num_workers: 4\n",
            "no_kan: False\n",
            "--------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/U-KAN/Seg_UKAN/train.py\", line 448, in <module>\n",
            "    main()\n",
            "  File \"/content/U-KAN/Seg_UKAN/train.py\", line 278, in main\n",
            "    model = model.cuda()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 916, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 916, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 314, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    }
  ]
}